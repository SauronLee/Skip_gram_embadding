# Skip_gram_model_embedding


SIST研究生発表のために

EC2-p2.xlargeで使う2hがかかるんです、wikiコーパス(20200501)~300mb->180mb(preprocessed)

'word_preprocessing.py --text wiki'

'python skip_gram_model.py --preprocessed_text preprocessed_text'